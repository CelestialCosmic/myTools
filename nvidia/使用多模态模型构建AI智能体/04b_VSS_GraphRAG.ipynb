{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adbb04a4",
   "metadata": {},
   "source": [
    "<center><a href=\"https://www.nvidia.cn/training/\"><img src=\"https://dli-lms.s3.amazonaws.com/assets/general/DLI_Header_White.png\" width=\"400\" height=\"186\" /></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2e5be5",
   "metadata": {},
   "source": [
    "# 4b. VSS 第二部分：问答和 Graph-RAG \n",
    "\n",
    "在上一个实验中，我们学习了如何使用 NVIDIA 的[视频搜索和摘要 AI 智能体](https://build.nvidia.com/nvidia/video-search-and-summarization/blueprintcard)来进行视频摘要。本实验将探索用户如何向这个 AI 智能体提问视频内容相关的问题。\n",
    "\n",
    "#### 学习目标:\n",
    "本文档的目标是：\n",
    "- 通过 VSS REST API 探索视频的问答\n",
    "- 了解 Graph-RAG（图形-RAG）组件\n",
    "- 在 Neo4J 中可视化知识图谱\n",
    "- 使用 Vector-RAG 进行问答（无 Graph-RAG）\n",
    "\n",
    "## 使用 VSS 执行问答（Q&A）任务\n",
    "\n",
    "VSS 通过 **Vector-RAG** 和 **Graph-RAG** 支持问答（Q&A）功能。 Vector-RAG 是实时流处理的唯一支持方法，而 Graph-RAG 专门用于基于视频的查询。\n",
    "\n",
    "**使用 Vector-RAG 执行问答任务：** VLM 生成的标题及其嵌入保存在 Milvus 数据库中。给定查询时，检索出最相关的前五个块，使用 ```llama-3.2-nv-rerankqa-1b-v2``` 重新排序，然后传给 LLM 生成最终答案。\n",
    "\n",
    "**使用 Graph-RAG  执行问答任务：** 为了捕获 VLM 生成的复杂信息，在处理视频过程中构建并存储知识图谱。使用 LLM 将密集的标题转换为一组节点、边及相关属性。该知识图谱存储在图数据库中。使用 ```llama-3.2-nv-embedqa-1b-v2``` 生成的标题和嵌入也与这些实体相关联。通过使用 Graph-RAG  技术，LLM 可以访问此信息以提取问答的关键信息。\n",
    "\n",
    "![VSS CA-RAG 图示](images/VSS_CA-RAG.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b630aa2",
   "metadata": {},
   "source": [
    "## 4.1 设置环境"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9ff1db",
   "metadata": {},
   "source": [
    "我们使用与上一个实验相同的 VSS 服务器。确认一下它已正常运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff261170",
   "metadata": {},
   "outputs": [],
   "source": [
    "warehouse_video = \"data/warehouse.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c884ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"via-server\" #e.g., 0.0.0.0 or localhost\n",
    "port = \"8000\" #e.g., 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcf4459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import yaml\n",
    "\n",
    "vss_url = f\"http://{host}:{port}\"\n",
    "\n",
    "ready_check_url = f\"{vss_url}/health/ready\"\n",
    "response = requests.get(ready_check_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(f\"Service is ready.\")\n",
    "else:\n",
    "    print(f\"Service is not ready. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70984408",
   "metadata": {},
   "source": [
    "## 4.2 探索视频问答\n",
    "\n",
    "请参考之前的实验，以探索所有 REST API 端点。下面用 REST API 上传文件，开启视频处理并启用聊天，然后提几个问题试试。\n",
    "\n",
    "<!-- ![仓库场景](images/warehouse.png) -->\n",
    "\n",
    "<video width=\"1000 \" height=\" \" \n",
    "       src=\"data/warehouse.mp4\"  \n",
    "       controls>\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f219ba1",
   "metadata": {},
   "source": [
    "### 4.2.1 上传视频文件\n",
    "\n",
    "让我们先上传一个视频，并从响应中保存文件 ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12f6251",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_url = f\"{vss_url}/files\"\n",
    "files = {'file': ('filename_with_extension', open(warehouse_video, 'rb'))}\n",
    "\n",
    "response = requests.post(upload_url, data={'purpose': 'vision', 'media_type': 'video'}, files=files)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    video_id=response.json().get('id')\n",
    "    print(\"Video Uploaded\")\n",
    "    print(f\"Video file ID: {video_id}\")\n",
    "else:\n",
    "    print(f\"Failed to upload file. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868a3f13",
   "metadata": {},
   "source": [
    "### 4.2.2 视频摄取（Ingestion）和处理\n",
    "\n",
    "接下来，我们处理视频以生成密集描述和知识图谱。这个步骤可能需要几分钟。\n",
    "- 首先，设置提示词\n",
    "- 然后，调用总结 API 来摄取视频\n",
    "- 请注意，这里将 ```enable_chat``` 设置为 True，以创建知识图谱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb5cf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = {\n",
    "    \"vlm_prompt\": \"You are a warehouse monitoring system. Describe the events in this warehouse and look for any anomalies. \"\n",
    "                            \"Start each sentence with start and end timestamp of the event.\",\n",
    "    \n",
    "    \"caption_summarization\": \"You will be given captions from sequential clips of a video. Aggregate captions in the format \"\n",
    "                             \"start_time:end_time:caption based on whether captions are related to one another or create a continuous scene.\",\n",
    "    \n",
    "    \"summary_aggregation\": \"Based on the available information, generate a summary that captures the important events in the video. \"\n",
    "                           \"The summary should be organized chronologically and in logical sections. This should be a concise, \"\n",
    "                           \"yet descriptive summary of all the important events. The format should be intuitive and easy for a \"\n",
    "                           \"user to read and understand what happened. Format the output in Markdown so it can be displayed nicely.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db54654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(prompts, video_id=video_id):\n",
    "    \n",
    "    process_video_url = f\"{vss_url}/summarize\"\n",
    "\n",
    "    payload = {\n",
    "        \"id\": video_id,\n",
    "        \"prompt\": prompts['vlm_prompt'],\n",
    "        \"caption_summarization_prompt\": prompts['caption_summarization'],\n",
    "        \"summary_aggregation_prompt\": prompts['summary_aggregation'],\n",
    "        \"model\": \"vila-1.5\",\n",
    "        \"chunk_duration\": 10,\n",
    "        \"chunk_overlap_duration\": 0,\n",
    "        \"summarize\": False,\n",
    "        \"enable_chat\": True,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(process_video_url, json=payload)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            response_data = response.json()\n",
    "            # Extracting the summary content\n",
    "            summary = response_data.get('choices', [])[0].get('message', {}).get('content', '')\n",
    "            return summary if summary else \"No content received.\"\n",
    "        else:\n",
    "            return f\"Failed to summarize. Status code: {response.status_code}. Response: {response.text}\"\n",
    "    \n",
    "    except requests.RequestException as e:\n",
    "        return f\"An error occurred: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fddd32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_video(prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73e6356",
   "metadata": {},
   "source": [
    "### 4.2.3 提问\n",
    "\n",
    "一旦视频处理完成，就可以调用 ```/chat/completions``` 端点来提问\n",
    "\n",
    "![问答端点](images/qna_swagger.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab10bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qna(query, video_id=video_id):\n",
    "\n",
    "    qna_url = f\"{vss_url}/chat/completions\"\n",
    "\n",
    "    payload = {\n",
    "        \"id\": video_id,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"content\": query,\n",
    "                \"role\": \"user\",\n",
    "            }\n",
    "        ],\n",
    "        \"model\": \"vila-1.5\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(qna_url, json=payload)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            response_data = response.json()\n",
    "            # Extracting the answer content\n",
    "            answer = response_data.get(\"choices\", [])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "            return answer if answer else \"No answer received.\"\n",
    "        else:\n",
    "            return f\"Failed to get a response. Status code: {response.status_code}. Response: {response.text}\"\n",
    "    \n",
    "    except requests.RequestException as e:\n",
    "        return f\"An error occurred: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6de7e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qna(\"Was there any forklift in the scene?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df344cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "qna(\"Was the worker carrying the box wearing PPE?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e529e6-27f1-43ea-93f2-66e5ef9e10d1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4.3 理解 Graph-RAG  组件\n",
    "\n",
    "![GraphRAG 图示](images/GraphRAG.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81f5663",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4.3.1 G-提取/索引（G-Extraction/Indexing）\n",
    "\n",
    "### 密集标题到图的转换:\n",
    "图提取器使用 LLM 来分析密集标题或任何文本输入，识别文本中的关键实体、动作和关系。\n",
    "\n",
    "#### 示例:\n",
    "给定一个关于仓库视频场景的标题，如：  \n",
    "*“一个工人在传送带上放置了一个重箱子，由于放置不当，箱子掉了。”*  \n",
    "\n",
    "- LLM 可以提取的实体包括：\n",
    "  - **工人**（人）\n",
    "  - **箱子**（物体）\n",
    "  - **传送带**（设备）\n",
    "\n",
    "- 识别出的关系可能包括：\n",
    "  - **“工人在传送带上放置箱子”**\n",
    "  - **“箱子因放置不当而掉落”**\n",
    "\n",
    "这些实体和关系在 Neo4j 图中表示为节点和边。用 `nvidia/nv-embedqa-e5-v5` 生成的标题和嵌入也与这些实体相关联。这些能为用户查询提供描述性的答案。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e8ac77",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4.3.2 G-检索器（G-Retriever）\n",
    "\n",
    "### Cypher 查询生成:\n",
    "图检索器利用 LLM 处理用户查询，并将其翻译为适合基于图搜索的结构化 cypher 查询。\n",
    "\n",
    "#### 示例:\n",
    "如果用户的查询是：  \n",
    "*“是什么导致箱子掉落的？”*  \n",
    "\n",
    "- LLM 确定关键实体（例如：“箱子”）和所需信息（例如：掉落的原因）。  \n",
    "- 然后生成一个结构化的 cypher 查询，以供图使用：\n",
    "\n",
    "```cypher\n",
    "MATCH (b:Object)-[:PLACED_ON]->(c:Equipment), (b)-[:FALLS_DUE_TO]->(r:Reason)\n",
    "WHERE b.name = 'Box'\n",
    "RETURN r\n",
    "```\n",
    "\n",
    "在知识图谱上执行这个查询，可以检索相关信息，让用户能查询图中的复杂关系。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da26509",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4.3.3 G-生成（G-Generation）\n",
    "\n",
    "一旦图检索器处理用户查询并从知识图谱中获取相关子图（Sub-graph），比如实体、关系和标题，**G-生成**利用 LLM 分析并综合检索到的数据，生成一个连贯且有意义的响应。\n",
    "\n",
    "### 示例:\n",
    "如果用户的查询是：  \n",
    "*\"是什么导致箱子掉落的？\"*  \n",
    "\n",
    "图检索器可能会获取包含的子图：\n",
    "- **节点**: \n",
    "  - 对象 (**箱子**)\n",
    "  - 设备 (**传送带**)\n",
    "  - 原因 (**放置不当**)\n",
    "- **关系**:\n",
    "  - **“箱子放置在传送带上”**\n",
    "  - **“箱子因放置不当而掉落”**\n",
    "- **标题**:\n",
    "  - **“一名工人在传送带上放置了一个重箱子，箱子因放置不当而掉落。”**\n",
    "\n",
    "G-生成会处理这些数据，将图结构及其属性结合起来，生成一个类似于：  \n",
    "*\"箱子掉落是因为它放置不当在传送带上。\"*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa118df5",
   "metadata": {},
   "source": [
    "### 我们再试几个问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a72ab7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "qna(\"What could be some possible safety issues in this warehouse?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee08e250",
   "metadata": {},
   "outputs": [],
   "source": [
    "qna(\"When did the worker place the caution tape?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265b0b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "qna(\"Describe the warehouse setting in detail.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b3f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qna(\"Enter your question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4752fddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qna(\"Enter your question\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8ee070",
   "metadata": {},
   "source": [
    "# 4.4  Graph-RAG  可视化\n",
    "\n",
    "这部分将探索并可视化存储在 Neo4j 数据库中的知识图谱。通过 Neo4j Python 库，我们将可以通过查询来获取图的一部分，并可视化以更好地理解。这种可视化有助于检查图中的结构和关系，提供数据库中存储数据的清晰表示。\n",
    "\n",
    "接下来的单元将生成指向 Neo4J 仪表板（dashboard）的链接。首先，将本 notebook 的网址（截止到 `.com`）复制到 `my_url` 中。\n",
    "\n",
    "点击生成的链接后，输入 VSS 启动配置中设置的用户名和密码。\n",
    "- 例如：\n",
    "  - 用户名: neo4j\n",
    "  - 密码: password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380aa836",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "my_url = \"COPY_NOTEBOOK_URL\"\n",
    "my_url = my_url.rsplit(\".com\", 1)[0] + \".com\"\n",
    "neo4j_port = 64018\n",
    "\n",
    "link_html = f'<a href=\"{my_url}:{neo4j_port}\" target=\"_blank\">点击这里打开 Neo4j 可视化仪表盘</a>'\n",
    "display(HTML(link_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd949c5",
   "metadata": {},
   "source": [
    "## 来自 Neo4j 可视化仪表盘的示例图\n",
    "\n",
    "![Graph Diagram](images/graph_neo4j.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8b799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "\n",
    "def visualize_neo4j_query(query, host=\"graph-db\", port=7687, user=\"neo4j\", password=\"password\"):\n",
    "    try:\n",
    "        graph = Graph(f\"bolt://{host}:{port}\", auth=(user, password))\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to Neo4j: {e}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        result = graph.run(query)\n",
    "        G = nx.DiGraph()\n",
    "\n",
    "        for record in result:\n",
    "            path = record[\"p\"]\n",
    "            for rel in path.relationships:\n",
    "                start_node = rel.start_node\n",
    "                end_node = rel.end_node\n",
    "\n",
    "                start_label = start_node.get(\"name\", start_node.get(\"id\", f\"Node_{start_node.identity}\"))\n",
    "                end_label = end_node.get(\"name\", end_node.get(\"id\", f\"Node_{end_node.identity}\"))\n",
    "\n",
    "                # Wrap labels for better readability if they are too long\n",
    "                start_label = '\\n'.join(textwrap.wrap(start_label, width=20))\n",
    "                end_label = '\\n'.join(textwrap.wrap(end_label, width=20))\n",
    "\n",
    "                G.add_node(start_label)\n",
    "                G.add_node(end_label)\n",
    "                G.add_edge(start_label, end_label, label=rel.__class__.__name__)\n",
    "\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        pos = nx.spring_layout(G, seed=42, k=0.5, iterations=50)\n",
    "        \n",
    "        nx.draw_networkx_nodes(G, pos, node_color='lightgreen', node_size=2500)\n",
    "        nx.draw_networkx_labels(G, pos, font_size=8)\n",
    "        edges = nx.draw_networkx_edges(G, pos, arrowstyle='-|>', arrowsize=10)\n",
    "        edge_labels = nx.get_edge_attributes(G, 'label')\n",
    "        nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_color='blue')\n",
    "\n",
    "        plt.title(\"Neo4j Graph Visualization\")\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error running query or visualizing the graph: {e}\")\n",
    "\n",
    "\n",
    "def get_neo4j_query_text(query, host=\"graph-db\", port=7687, user=\"neo4j\", password=\"password\"):\n",
    "    try:\n",
    "        graph = Graph(f\"bolt://{host}:{port}\", auth=(user, password))\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to Neo4j: {e}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        result = graph.run(query)\n",
    "        output = []\n",
    "\n",
    "        for record in result:\n",
    "            path = record[\"p\"]\n",
    "            for rel in path.relationships:\n",
    "                start_node = rel.start_node\n",
    "                end_node = rel.end_node\n",
    "\n",
    "                start_label = start_node.get(\"name\", start_node.get(\"id\", f\"Node_{start_node.identity}\"))\n",
    "                end_label = end_node.get(\"name\", end_node.get(\"id\", f\"Node_{end_node.identity}\"))\n",
    "\n",
    "                output.append(f\"Person: {start_label} placed an item: {end_label}\")\n",
    "\n",
    "        if not output:\n",
    "            return \"No results found.\"\n",
    "\n",
    "        return \"\\n\".join(output)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error running query or processing the results: {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fec4d62",
   "metadata": {},
   "source": [
    "## 部分 4.4.1 Cypher 查询\n",
    "\n",
    "<span style=\"color:red\"><b>注意: 您可能需要根据实际生成的图形修改以下 Cypher 查询中的实体和关系名称</b></span>\n",
    "\n",
    "#### 可视化谁穿着什么\n",
    "\n",
    "让我们看看与包含“WEARS”关键字的所有实体相关的子图:\n",
    "\n",
    "以下 Cypher 查询检索并可视化与人们穿着物品的关系。它匹配图中的所有 `WEARS` 关系，并返回路径，以便更好地理解这些连接。\n",
    "\n",
    "**Cypher 查询:**\n",
    "```cypher\n",
    "MATCH p=()-[r:WEARS]->() \n",
    "RETURN p\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0f66b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_neo4j_query(\"MATCH p=()-[r:WEARS]->() RETURN p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29104dd4",
   "metadata": {},
   "source": [
    "#### 可视化一个 id 为 \"worker\" 的携带物品的人的子图\n",
    "\n",
    "下面的 Cypher 查询检索关于一个特定人（通过 `worker` 标识）携带物品的信息。它匹配人和物品之间的 `CARRIES` 关系，返回路径和动作的细节。\n",
    "\n",
    "**Cypher 查询:**\n",
    "\n",
    "```cypher\n",
    "MATCH p=(person)-[r:CARRIES]->(item)\n",
    "WHERE person.id = 'worker'\n",
    "RETURN p\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0382472",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_neo4j_query(\"MATCH p=(person)-[r:CARRIES]->(item) WHERE person.id = 'worker' RETURN p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54223a78",
   "metadata": {},
   "source": [
    "#### 使用 Cypher 查询获取特定节点\n",
    "\n",
    "让我们看看我们的系统将如何回答“描述携带箱子的人。”我们之前问过这个问题。\n",
    "\n",
    "下面的 Cypher 查询检索携带一个 `id` 为 \"box\" 物品的人的信息。它匹配一个人和物品之间的 `CARRIES` 关系，并返回放置者和他们放置的物品的细节。\n",
    "\n",
    "**Cypher 查询:**\n",
    "\n",
    "```cypher\n",
    "MATCH p=(person)-[r:CARRIES]->(item)\n",
    "WHERE item.id = \"box\"\n",
    "RETURN p\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6a4ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "MATCH p=(person)-[r:CARRIES]->(item)\n",
    "WHERE item.id = \"box\"\n",
    "RETURN p\n",
    "\"\"\"\n",
    "\n",
    "text_output = get_neo4j_query_text(query)\n",
    "print(text_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48136e39",
   "metadata": {},
   "source": [
    "## 接下来"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1120e6",
   "metadata": {},
   "source": [
    "恭喜您！到这里课程的全部内容就结束了，是时候在最后评估中检验您学到的知识了。祝您好运！"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
